{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22c3cd-0bb8-4acb-9737-e91b186ba841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the path to the utils folder to sys.path\n",
    "utils_path = Path('/shared/Wildfire/test_hv_logration_temp/uavsar-wildfire-main/python').resolve()\n",
    "sys.path.append(str(utils_path))\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from process_utils import (preprocess_data,\n",
    "                           superpixel_segmentation,\n",
    "                            tv_denoise, \n",
    "                            preprocess_for_merge)\n",
    "from rio_utils import (reproject_arr_to_match_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5eef15-08eb-4c45-9b69-b61fa52c050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens a GeoTIFF and loads the backscatter values and profile\n",
    "def open_one(path):\n",
    "    with rasterio.open(path) as ds:\n",
    "        band = ds.read(1)\n",
    "        profile = ds.profile\n",
    "    return band, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034705fb-039d-4a75-9a2d-32d61a8798c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc_filter(img):\n",
    "    img_deg = np.rad2deg(img)\n",
    "    mask = (img_deg < 20) | (img_deg > 60)\n",
    "    img_deg[mask] = 999\n",
    "    return img_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3021ac0-a776-4774-93f8-90e4a3b9afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(data, weight):\n",
    "    mask = np.isnan(data)\n",
    "    data[mask] = 9999\n",
    "    data_tv = tv_denoise(data, weight)\n",
    "    data_tv[mask] = np.nan\n",
    "\n",
    "    return data_tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b2c28-f0fc-47fc-b7c1-af2e76ed717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.ndimage import generic_filter\n",
    "\n",
    "# def fill_nan(arr, size=3):\n",
    "#     \"\"\" Helper function to replace NaN with local mean. \"\"\"\n",
    "#     arr_filled = np.copy(arr)\n",
    "#     nan_mask = np.isnan(arr)\n",
    "    \n",
    "#     # Only apply the filter to regions that contain NaN\n",
    "#     if np.any(nan_mask):\n",
    "#         for i in range(arr.shape[0]):\n",
    "#             for j in range(arr.shape[1]):\n",
    "#                 if nan_mask[i, j]:\n",
    "#                     # Define a small window around the NaN pixel\n",
    "#                     x_start = max(i - size // 2, 0)\n",
    "#                     x_end = min(i + size // 2 + 1, arr.shape[0])\n",
    "#                     y_start = max(j - size // 2, 0)\n",
    "#                     y_end = min(j + size // 2 + 1, arr.shape[1])\n",
    "                    \n",
    "#                     # Get the region and compute the mean ignoring NaNs\n",
    "#                     region = arr[x_start:x_end, y_start:y_end]\n",
    "                    \n",
    "#                     # Check if the region contains any valid (non-NaN) values\n",
    "#                     if np.any(~np.isnan(region)):\n",
    "#                         mean_val = np.nanmean(region)\n",
    "#                     else:\n",
    "#                         # If no valid values, set to a default value (e.g., 0 or mean of entire array)\n",
    "#                         mean_val = np.nanmean(arr)  # Or use 0 or another placeholder\n",
    "#                     arr_filled[i, j] = mean_val\n",
    "                    \n",
    "#     return arr_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c87a4-7058-4fb3-8276-1073b6f384ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def weighted_inc_merge(img_0, img_1, img_2, img_3, inc_0, inc_1, inc_2, inc_3):\n",
    "    # Validate pixel values (ensuring they are within the valid range for both images and incidence angles)\n",
    "    valid_pixel_0 = ~np.isnan(img_0) & (inc_0 >= 25) & (inc_0 <= 65)\n",
    "    valid_pixel_1 = ~np.isnan(img_1) & (inc_1 >= 25) & (inc_1 <= 65)\n",
    "    valid_pixel_2 = ~np.isnan(img_2) & (inc_2 >= 25) & (inc_2 <= 65)\n",
    "    valid_pixel_3 = ~np.isnan(img_3) & (inc_3 >= 25) & (inc_3 <= 65)\n",
    "\n",
    "    # Invalid pixel logic for handling missing or invalid data\n",
    "    invalid_pixel_0 = np.isnan(img_0) | (inc_0 < 25) | (inc_0 > 65)\n",
    "    invalid_pixel_1 = np.isnan(img_1) | (inc_1 < 25) | (inc_1 > 65)\n",
    "    invalid_pixel_2 = np.isnan(img_2) | (inc_2 < 25) | (inc_2 > 65)\n",
    "    invalid_pixel_3 = np.isnan(img_3) | (inc_3 < 25) | (inc_3 > 65)\n",
    "\n",
    "    # Weight calculation (ensuring proper weighting per valid pixel)\n",
    "    total_inc = inc_0 + inc_1 + inc_2 + inc_3\n",
    "    w0 = np.where(total_inc > 0, inc_0 / total_inc, 0)\n",
    "    w1 = np.where(total_inc > 0, inc_1 / total_inc, 0)\n",
    "    w2 = np.where(total_inc > 0, inc_2 / total_inc, 0)\n",
    "    w3 = np.where(total_inc > 0, inc_3 / total_inc, 0)\n",
    "\n",
    "    # Prepare the output array\n",
    "    img_merged = np.empty_like(img_0)\n",
    "    img_merged[:] = np.nan\n",
    "\n",
    "    # Combine valid pixels using weighted sum\n",
    "    img_merged[valid_pixel_0] = (w0 * img_0)[valid_pixel_0] + (w1 * img_1)[valid_pixel_0] + (w2 * img_2)[valid_pixel_0] + (w3 * img_3)[valid_pixel_0]\n",
    "    img_merged[valid_pixel_1] = (w0 * img_0)[valid_pixel_1] + (w1 * img_1)[valid_pixel_1] + (w2 * img_2)[valid_pixel_1] + (w3 * img_3)[valid_pixel_1]\n",
    "    img_merged[valid_pixel_2] = (w0 * img_0)[valid_pixel_2] + (w1 * img_1)[valid_pixel_2] + (w2 * img_2)[valid_pixel_2] + (w3 * img_3)[valid_pixel_2]\n",
    "    img_merged[valid_pixel_3] = (w0 * img_0)[valid_pixel_3] + (w1 * img_1)[valid_pixel_3] + (w2 * img_2)[valid_pixel_3] + (w3 * img_3)[valid_pixel_3]\n",
    "\n",
    "    # Combine cases where one pixel is valid and the others are not\n",
    "    img_merged[valid_pixel_0 & invalid_pixel_1 & invalid_pixel_2 & invalid_pixel_3] = img_0[valid_pixel_0 & invalid_pixel_1 & invalid_pixel_2 & invalid_pixel_3]\n",
    "    img_merged[valid_pixel_1 & invalid_pixel_0 & invalid_pixel_2 & invalid_pixel_3] = img_1[valid_pixel_1 & invalid_pixel_0 & invalid_pixel_2 & invalid_pixel_3]\n",
    "    img_merged[valid_pixel_2 & invalid_pixel_0 & invalid_pixel_1 & invalid_pixel_3] = img_2[valid_pixel_2 & invalid_pixel_0 & invalid_pixel_1 & invalid_pixel_3]\n",
    "    img_merged[valid_pixel_3 & invalid_pixel_0 & invalid_pixel_1 & invalid_pixel_2] = img_3[valid_pixel_3 & invalid_pixel_0 & invalid_pixel_1 & invalid_pixel_2]\n",
    "\n",
    "    \n",
    "    img_merged = fill_nan(img_merged)\n",
    "    return img_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c9cea-1ca0-452c-99da-bba4ffcadf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.ndimage import generic_filter\n",
    "\n",
    "# def fill_nan(arr, size=3):\n",
    "#     \"\"\" Helper function to replace NaN with local mean. \"\"\"\n",
    "#     arr_filled = np.copy(arr)\n",
    "#     nan_mask = np.isnan(arr)\n",
    "    \n",
    "#     # Only apply the filter to regions that contain NaN\n",
    "#     if np.any(nan_mask):\n",
    "#         for i in range(arr.shape[0]):\n",
    "#             for j in range(arr.shape[1]):\n",
    "#                 if nan_mask[i, j]:\n",
    "#                     # Define a small window around the NaN pixel\n",
    "#                     x_start = max(i - size // 2, 0)\n",
    "#                     x_end = min(i + size // 2 + 1, arr.shape[0])\n",
    "#                     y_start = max(j - size // 2, 0)\n",
    "#                     y_end = min(j + size // 2 + 1, arr.shape[1])\n",
    "                    \n",
    "#                     # Get the region and compute the mean ignoring NaNs\n",
    "#                     region = arr[x_start:x_end, y_start:y_end]\n",
    "                    \n",
    "#                     # Check if the region contains any valid (non-NaN) values\n",
    "#                     if np.any(~np.isnan(region)):\n",
    "#                         mean_val = np.nanmean(region)\n",
    "#                     else:\n",
    "#                         # If no valid values, set to a default value (e.g., 0 or mean of entire array)\n",
    "#                         mean_val = np.nanmean(arr)  # Or use 0 or another placeholder\n",
    "#                     arr_filled[i, j] = mean_val\n",
    "                    \n",
    "#     return arr_filled\n",
    "\n",
    "# def weighted_inc_merge(img_0, img_1, img_2, img_3, inc_0, inc_1, inc_2, inc_3):\n",
    "#     # Validate pixel values (ensuring they are within the valid range for all images)\n",
    "#     valid_pixel_0 = ~np.isnan(img_0) & (inc_0 >= 20) & (inc_0 <= 60)\n",
    "#     valid_pixel_1 = ~np.isnan(img_1) & (inc_1 >= 20) & (inc_1 <= 60)\n",
    "#     valid_pixel_2 = ~np.isnan(img_2) & (inc_2 >= 20) & (inc_2 <= 60)\n",
    "#     valid_pixel_3 = ~np.isnan(img_3) & (inc_3 >= 20) & (inc_3 <= 60)\n",
    "\n",
    "#     # Calculate weights (ensuring no division by zero)\n",
    "#     total_inc = inc_0 + inc_1 + inc_2 + inc_3\n",
    "#     w0 = np.where(total_inc != 0, inc_0 / total_inc, 0)\n",
    "#     w1 = np.where(total_inc != 0, inc_1 / total_inc, 0)\n",
    "#     w2 = np.where(total_inc != 0, inc_2 / total_inc, 0)\n",
    "#     w3 = np.where(total_inc != 0, inc_3 / total_inc, 0)\n",
    "\n",
    "#     # Prepare the output array\n",
    "#     img_merged = np.empty_like(img_0)\n",
    "#     img_merged[:] = np.nan  # Initialize with NaNs\n",
    "\n",
    "#     # Merge valid pixels from all four images based on weights\n",
    "#     img_merged[valid_pixel_0] = w0[valid_pixel_0] * img_0[valid_pixel_0]\n",
    "#     img_merged[valid_pixel_1] = w1[valid_pixel_1] * img_1[valid_pixel_1]\n",
    "#     img_merged[valid_pixel_2] = w2[valid_pixel_2] * img_2[valid_pixel_2]\n",
    "#     img_merged[valid_pixel_3] = w3[valid_pixel_3] * img_3[valid_pixel_3]\n",
    "\n",
    "#     # Handle overlapping valid pixels by summing the weighted values\n",
    "#     img_merged_sum_weights = w0 + w1 + w2 + w3\n",
    "#     img_merged = img_merged / img_merged_sum_weights  # Normalize the weighted sum\n",
    "\n",
    "#     # Fill completely missing pixels using local averaging (to handle edge NaNs)\n",
    "#     img_merged = fill_nan(img_merged)\n",
    "\n",
    "#     return img_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1955d-cf8c-43a8-a232-9660f7c22670",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/shared/Wildfire/Bety_wildfire_project/Bety_data_test/Hv_logratio_rectangle_45km_40km\")\n",
    "tifs = sorted(list(data_dir.rglob('./*_rtc_box_cropped*.tif')))\n",
    "\n",
    "tifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594edae-9fbc-491a-b8eb-b7198f09b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/shared/Wildfire/Bety_wildfire_project/Bety_data_test/Hv_logratio_rectangle_45km_40km\")\n",
    "incs = sorted(list(data_dir.rglob('./*inc_box_crop*.tif')))\n",
    "incs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565b3d7a-27a1-49c8-9ab9-130e1e1d23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands, profiles = zip(*map(open_one, tifs))\n",
    "\n",
    "bands = list(bands)\n",
    "for i in range(len(bands)):\n",
    "    bands[i] = preprocess_for_merge(bands[i]) # mask out the missing data after RTC. Scale the values to ensure consistency\n",
    "\n",
    "pre_0 = bands[0]\n",
    "post_0 = bands[1]\n",
    "pre_1 = bands[2]\n",
    "post_1 = bands[3]\n",
    "pre_2 = bands[4]\n",
    "post_2 = bands[5]\n",
    "pre_3 = bands[6]\n",
    "post_3 = bands[7]\n",
    "\n",
    "profile_pre0 = profiles[0]\n",
    "profile_post0 = profiles[1]\n",
    "profile_pre1 = profiles[2]\n",
    "profile_post1 = profiles[3]\n",
    "profile_pre2 = profiles[4]\n",
    "profile_post2 = profiles[5]\n",
    "profile_pre3 = profiles[6]\n",
    "profile_post3 = profiles[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e9ed2-d703-4971-a170-96b89c19b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_bands, inc_profiles = zip(*map(open_one, incs))\n",
    "\n",
    "inc_bands = list(inc_bands)\n",
    "for i in range(len(inc_bands)):\n",
    "    inc_bands[i] = inc_filter(inc_bands[i]) # convert angle from radian to degree. Filter out the bad angles\n",
    "\n",
    "pre_inc_0 = inc_bands[0]\n",
    "post_inc_0 = inc_bands[1]\n",
    "pre_inc_1 = inc_bands[2]\n",
    "post_inc_1 = inc_bands[3]\n",
    "pre_inc_2 = inc_bands[4]\n",
    "post_inc_2 = inc_bands[5]\n",
    "pre_inc_3 = inc_bands[6]\n",
    "post_inc_3 = inc_bands[7]\n",
    "\n",
    "profile_pre0_inc = inc_profiles[0]\n",
    "profile_post0_inc = inc_profiles[1]\n",
    "profile_pre1_inc = inc_profiles[2]\n",
    "profile_post1_inc = inc_profiles[3]\n",
    "profile_pre2_inc = inc_profiles[4]\n",
    "profile_post2_inc = inc_profiles[5]\n",
    "profile_pre3_inc = inc_profiles[6]\n",
    "profile_post3_inc = inc_profiles[7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e8bb8-bee5-4038-b168-3be5619f6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampling = 'bilinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c92113-6756-40f3-9853-b4098a78b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject the original bands to match the profile of pre_0\n",
    "pre_0, _ = reproject_arr_to_match_profile(pre_0, profile_pre0, profile_pre0, resampling=resampling)\n",
    "pre_0 = pre_0[0]\n",
    "post_0, _ = reproject_arr_to_match_profile(post_0, profile_post0, profile_pre0, resampling=resampling)\n",
    "post_0 = post_0[0]\n",
    "pre_1, _ = reproject_arr_to_match_profile(pre_1, profile_pre1, profile_pre0, resampling=resampling)\n",
    "pre_1 = pre_1[0]\n",
    "post_1, _ = reproject_arr_to_match_profile(post_1, profile_post1, profile_pre0, resampling=resampling)\n",
    "post_1 = post_1[0]\n",
    "pre_2, _ = reproject_arr_to_match_profile(pre_2, profile_pre2, profile_pre0, resampling=resampling)\n",
    "pre_2 = pre_2[0]\n",
    "post_2, _ = reproject_arr_to_match_profile(post_2, profile_post2, profile_pre0, resampling=resampling)\n",
    "post_2 = post_2[0]\n",
    "pre_3, _ = reproject_arr_to_match_profile(pre_3, profile_pre3, profile_pre0, resampling=resampling)\n",
    "pre_3 = pre_3[0]\n",
    "post_3, _ = reproject_arr_to_match_profile(post_3, profile_post3, profile_pre0, resampling=resampling)\n",
    "post_3 = post_3[0]\n",
    "\n",
    "# Reproject the incidence bands to match the profile of pre_0\n",
    "pre_inc_0, _ = reproject_arr_to_match_profile(pre_inc_0, profile_pre0_inc, profile_pre0, resampling=resampling)\n",
    "pre_inc_0 = pre_inc_0[0]\n",
    "post_inc_0, _ = reproject_arr_to_match_profile(post_inc_0, profile_post0_inc, profile_pre0, resampling=resampling)\n",
    "post_inc_0 = post_inc_0[0]\n",
    "pre_inc_1, _ = reproject_arr_to_match_profile(pre_inc_1, profile_pre1_inc, profile_pre0, resampling=resampling)\n",
    "pre_inc_1 = pre_inc_1[0]\n",
    "post_inc_1, _ = reproject_arr_to_match_profile(post_inc_1, profile_post1_inc, profile_pre0, resampling=resampling)\n",
    "post_inc_1 = post_inc_1[0]\n",
    "pre_inc_2, _ = reproject_arr_to_match_profile(pre_inc_2, profile_pre2_inc, profile_pre0, resampling=resampling)\n",
    "pre_inc_2 = pre_inc_2[0]\n",
    "post_inc_2, _ = reproject_arr_to_match_profile(post_inc_2, profile_post2_inc, profile_pre0, resampling=resampling)\n",
    "post_inc_2 = post_inc_2[0]\n",
    "pre_inc_3, _ = reproject_arr_to_match_profile(pre_inc_3, profile_pre3_inc, profile_pre0, resampling=resampling)\n",
    "pre_inc_3 = pre_inc_3[0]\n",
    "post_inc_3, _ = reproject_arr_to_match_profile(post_inc_3, profile_post3_inc, profile_pre0, resampling=resampling)\n",
    "post_inc_3 = post_inc_3[0]\n",
    "\n",
    "# Ensure the arrays match after reprojection, as they are now consistent in shape and profile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e8a45c-05d2-4a90-9557-ea3ff5e632a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can include pre_2, post_2, pre_inc_2, and post_inc_2 in the merge\n",
    "hv_0 = weighted_inc_merge(pre_0, pre_1, pre_2, pre_3, pre_inc_0, pre_inc_1, pre_inc_2, pre_inc_3)\n",
    "hv_1 = weighted_inc_merge(post_0, post_1, post_2, post_3, post_inc_0, post_inc_1, post_inc_2, post_inc_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16cbab6-ca65-4346-82f6-6925af6017c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hv_0 stats:\", np.nanmin(hv_0), np.nanmax(hv_0), np.isnan(hv_0).sum())\n",
    "print(\"hv_1 stats:\", np.nanmin(hv_1), np.nanmax(hv_1), np.isnan(hv_1).sum())\n",
    "print(\"valid log10 mask:\", np.sum((hv_0 > 0) & (hv_1 > 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361dd36-29fd-451d-ba44-e263270bf6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hv_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89922bc-80c1-4cbd-9c91-ca313969d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a6220-6a3a-4afd-8e03-992bfab355b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path_0 = \"/shared/Wildfire/Bety_wildfire_project/Bety_data_test/Hv_logratio_rectangle_45km_40km/bobcat_hv_0.tif\"\n",
    "output_path_1 = \"/shared/Wildfire/Bety_wildfire_project/Bety_data_test/Hv_logratio_rectangle_45km_40km/bobcat_hv_1.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51375e-38ab-47fd-b372-1fe83dadb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(output_path_0, \"w\", **profile_pre0) as dest:\n",
    "    dest.write(hv_0, 1)\n",
    "with rasterio.open(output_path_1, \"w\", **profile_pre0) as dest:\n",
    "    dest.write(hv_1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33041c1e-518e-43e9-a4dc-2852bb0c2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(10 * np.log10(hv_0/hv_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c421c-41df-458a-a135-d03238786a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
